{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32680b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS :\n",
    "\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ba9bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (2,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>Time_index2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16/12/2006 17:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16/12/2006 17:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16/12/2006 17:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16/12/2006 17:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16/12/2006 17:28:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date      Time  Global_active_power  \\\n",
       "timestamp                                                        \n",
       "2006-12-16 17:24:00  16/12/2006  17:24:00                4.216   \n",
       "2006-12-16 17:25:00  16/12/2006  17:25:00                5.360   \n",
       "2006-12-16 17:26:00  16/12/2006  17:26:00                5.374   \n",
       "2006-12-16 17:27:00  16/12/2006  17:27:00                5.388   \n",
       "2006-12-16 17:28:00  16/12/2006  17:28:00                3.666   \n",
       "\n",
       "                    Global_reactive_power  Voltage Global_intensity  \\\n",
       "timestamp                                                             \n",
       "2006-12-16 17:24:00                 0.418  234.840           18.400   \n",
       "2006-12-16 17:25:00                 0.436  233.630           23.000   \n",
       "2006-12-16 17:26:00                 0.498  233.290           23.000   \n",
       "2006-12-16 17:27:00                 0.502  233.740           23.000   \n",
       "2006-12-16 17:28:00                 0.528  235.680           15.800   \n",
       "\n",
       "                    Sub_metering_1 Sub_metering_2 Sub_metering_3  \\\n",
       "timestamp                                                          \n",
       "2006-12-16 17:24:00          0.000          1.000         17.000   \n",
       "2006-12-16 17:25:00          0.000          1.000         16.000   \n",
       "2006-12-16 17:26:00          0.000          2.000         17.000   \n",
       "2006-12-16 17:27:00          0.000          1.000         17.000   \n",
       "2006-12-16 17:28:00          0.000          1.000         17.000   \n",
       "\n",
       "                             Time_index2  \n",
       "timestamp                                 \n",
       "2006-12-16 17:24:00  16/12/2006 17:24:00  \n",
       "2006-12-16 17:25:00  16/12/2006 17:25:00  \n",
       "2006-12-16 17:26:00  16/12/2006 17:26:00  \n",
       "2006-12-16 17:27:00  16/12/2006 17:27:00  \n",
       "2006-12-16 17:28:00  16/12/2006 17:28:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATABASE :\n",
    "\n",
    "data = pd.read_csv('DATABASE.txt', sep=\";\", header=None, na_values=['?'])\n",
    "\n",
    "data = data[:5000]\n",
    "\n",
    "data = data.rename(columns=data.iloc[0]).drop(data.index[0])\n",
    "\n",
    "data[\"Time_index2\"] = data[\"Date\"] + \" \" + data[\"Time\"]\n",
    "\n",
    "data[\"timestamp\"] = pd.to_datetime(data['Time_index2'], format='%d/%m/%Y %H:%M:%S')\n",
    "data.set_index(['timestamp'],inplace=True)\n",
    "\n",
    "data[\"Global_active_power\"] = data[\"Global_active_power\"].astype(float)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76da0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups databases :\n",
    "\n",
    "df_train = data[:2000]\n",
    "df_val = data[2000:3000]\n",
    "df_test = data[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bc0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Data :\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cols = ['Global_active_power']\n",
    "\n",
    "train_arr = scaler.fit_transform(df_train[cols])\n",
    "val_arr = scaler.transform(df_val[cols])\n",
    "test_arr = scaler.transform(df_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47151ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data :\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def transform_data(arr, seq_len):\n",
    "    x, y = [], []\n",
    "    for i in range(len(arr) - seq_len):\n",
    "        x_i = arr[i : i + seq_len]\n",
    "        y_i = arr[i + 1 : i + seq_len + 1]\n",
    "        x.append(x_i)\n",
    "        y.append(y_i)\n",
    "    x_arr = np.array(x).reshape(-1, seq_len)\n",
    "    y_arr = np.array(y).reshape(-1, seq_len)\n",
    "    x_var = Variable(torch.from_numpy(x_arr).float())\n",
    "    y_var = Variable(torch.from_numpy(y_arr).float())\n",
    "    return x_var, y_var\n",
    "seq_len = 100\n",
    "x_train, y_train = transform_data(train_arr, seq_len)\n",
    "x_val, y_val = transform_data(val_arr, seq_len)\n",
    "x_test, y_test = transform_data(test_arr, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3bd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lSTM :\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "    def forward(self, input, future=0, y=None):\n",
    "        outputs = []\n",
    "        # reset the state of LSTM\n",
    "        # the state is kept till the end of the sequence\n",
    "        h_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        c_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm(input_t, (h_t, c_t))\n",
    "            output = self.linear(h_t)\n",
    "            outputs += [output]\n",
    "        for i in range(future):\n",
    "            if y is not None and random.random() > 0.5:\n",
    "                output = y[:, [i]]  # teacher forcing\n",
    "            h_t, c_t = self.lstm(output, (h_t, c_t))\n",
    "            output = self.linear(h_t)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
